# 驾驶员行为实时检测系统技术报告 (Final Version)

## 1. 摘要

本项目开发了一套基于 **YOLOv8** 深度学习框架的驾驶员行为实时检测系统。针对驾驶舱环境下的小目标检测难题，本项目采用了**两阶段动态裁剪**算法与**精细化阈值**策略。实验表明，经过微调的 YOLOv8n 模型在 **抽烟 (Smoke)**、**手机使用 (Phone)** 和 **饮水 (Drink)** 三类行为上的 mAP@0.5 达到 **0.94**，显著优于通用目标检测模型，成功实现了高精度、低延迟的实时监控。

---

## 2. 深度学习算法优化

### 2.1 微调前后的性能差异对比
在项目初期，我们直接使用了在 COCO 数据集上预训练的 YOLOv8n 模型进行测试。虽然通用模型能识别 "cell phone" 或 "bottle"，但在驾驶员行为检测任务上存在显著缺陷：
-   **误检率高**: 常将驾驶员的手部动作（如摸脸）误识别为打电话。
-   **漏检严重**: 对“吸烟”这一非 COCO 类别完全无法识别；对车内暗光环境下的深色手机检测能力极差。

**微调后的提升**:
通过在专用数据集（7981张图像）上进行微调训练，模型性能实现了质的飞跃：
-   **mAP@0.5 提升**: 从通用模型的约 0.4~0.5 (针对相关类) 提升至 **0.94152**。
-   **类别补全**: 成功新增了 **Smoke** 类别，并实现了对微小烟头的高敏度检测。

### 2.2 核心创新：两阶段动态识别算法 (Two-Stage Dynamic Recognition)
为了解决监控广角镜头下“全景图中手机像素占比不足 1%”导致的特征丢失问题，我们提出并实现了一种**“先定位，后特写”**的级联检测算法。该算法模仿人类视觉系统的注意力机制，分为以下两个严格的阶段：

#### 阶段一：宏观驾驶员定位 (Stage 1: Driver Localization)
在第一阶段，系统并不急于识别具体的微小行为，而是专注于寻找“人”的位置。
-   **模型选择**: 动态加载标准 **YOLOv8n (COCO)** 模型作为“定位器 (Locator)”。
-   **任务目标**: 在全图 (Global View) 中高置信度地定位 `person` 类别。
-   **输出**: 获得驾驶员的原始边界框 coordinates $(x_1, y_1, x_2, y_2)$。这解决了专用模型（仅微调了Smoke/Phone/Drink）无法感知“人”在哪里的缺陷。

#### 阶段二：ROI 动态特写与微观推理 (Stage 2: ROI Zoom-in & Micro-Inference)
在获得驾驶员位置后，系统对感兴趣区域 (ROI) 进行智能处理，这是提升小目标检测精度的关键步骤：

1.  **非对称动态扩张 (ROI Expansion)**:
    为了防止驾驶员的手部动作（如拿着电话的手）超出原始的人体框，我们设计了非对称的扩展策略：
    -   **横向扩展**: 左右各增加 **35%** 宽度，确保覆盖肩部和手肘区域。
    -   **纵向扩展**: 向下增加 **50%** 高度，重点覆盖方向盘和手部操作区域。
    $$ x_{new\_1} = x_1 - w \times 0.35, \quad y_{new\_2} = y_2 + h \times 0.50 $$

2.  **超分辨率重采样 (Upsampling)**:
    将裁剪出的扩展区域 Resize 至模型标准输入尺寸 (640x640)。
    > **效果**: 原始画面中仅占 20x20 像素的“香烟”，在裁剪放大后可能占据 100x100 像素。这种物理分辨率的提升直接增强了卷积层对边缘纹理的提取能力。

3.  **微观行为推理**:
    将放大后的图像送入我们**微调后的专用 YOLOv8 模型**。此时模型仿佛在“近距离凝视”驾驶员，能够轻易识别出微小的烟头或黑色的手机屏幕。

4.  **坐标逆向映射**:
    最后，将局部坐标 $(x', y')$ 还原回全局坐标系 $(X, Y)$，完成最终的标注绘制：
    $$ X = x' + x_{ROI\_offset}, \quad Y = y' + y_{ROI\_offset} $$

### 2.3 工程级阈值调优
我们并未采用单一的全局置信度阈值，而是根据不同行为的风险等级和特征难度制定了差异化策略：
-   **Smoke (0.80)**: 极高阈值。因手指形状极易像烟，只有确信度极高时才报警，大幅降低了误报干扰。
-   **Drink (0.10)**: 极低阈值。考虑到饮水动作往往短暂且涉及视线遮挡，必须优先保证召回率 (Recall)，宁可多报不可漏报。

---

## 3. 系统架构与工程实现

### 3.1 道路监控检测的难点与挑战
在构建实际系统前，我们深入分析了道路监控场景的特殊性：
1.  **极小目标**: 摄像头通常位于车内顶部或侧上方，手机和香烟在画面中仅占极少像素，常规检测器极易漏检。
2.  **复杂光照**: 驾驶舱内光线随车辆行驶不断变化（如进出隧道、树荫），要求系统具备极强的鲁棒性。
3.  **实时性要求**: 危险行为稍纵即逝，系统必须在毫秒级内完成“采集-检测-报警”闭环。

### 3.2 系统架构设计
为应对上述挑战，系统采用了**前后端分离**的异步架构。

#### 后端设计 (FastAPI)
-   **异步流水线**: 采用 `async/await` 处理视频流 I/O，保证在处理高清视频上传时不阻塞主线程。
-   **模块解耦**: 将检测逻辑封装为独立的 `DetectionEngine` 类，与 Web 服务层完全解耦，便于后续替换更强的模型（如 YOLOv8s/m）。
-   **智能 NMS**: 自研了针对重叠框的非极大值抑制算法，当两个检测框 IoU > 0.45 时，智能剔除冗余结果，确保输出界面的整洁。

#### 前端设计 (Canvas Visualization)
前端摒弃了传统的粗糙矩形框，采用了 **"Precision Reticle" (精密光标)** 渲染风格：
-   **视觉通透**: 仅绘制边界框四角，中心通过透明度 (`alpha=0.05`) 填充，完全不遮挡驾驶员面部细节。
-   **信息分层**: 置信度与类别标签采用引线式标注，既保留了技术指标的严谨性，又提升了监控画面的现代化质感。

---

## 4. 实验结论

本系统通过算法层面的“微调+两阶段裁剪”和工程层面的“异步架构+精细化阈值”，成功构建了一套工业级的驾驶员行为检测方案。实验数据证明，系统在保持 50ms/帧 (CPU) 高性能推理的同时，将核心危险行为的检测精度提升至 94% 以上，有效解决了传统方案在小目标和复杂光照下的痛点。

---
**日期**: 2025年12月29日
