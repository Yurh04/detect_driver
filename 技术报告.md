# 驾驶员行为实时检测系统技术报告
>软件学院   
>于润昊  
>22379107

## 1. 摘要

本项目构建了一套基于 **YOLOv8** 深度学习框架的高精度驾驶员行为检测系统。针对路口监控等远距离视角下小目标检测难、误报率高的问题，我们创新性地提出并实现了 **"辅助定位 + 局部特写"** 的双模型二阶段检测架构。系统通过引入轻量级辅助模型精确定位驾驶员，配合主模型在裁剪区域内进行超低阈值推理，并结合 **NMS (非极大值抑制)** 与 **动态类别阈值过滤** 算法，显著解决了抽烟、喝水与打电话识别中的漏报与误报问题。

---

## 2. 核心挑战与解决方案

在实际开发过程中，我们通过测试路口监控视频发现以下核心挑战：
1. **小目标失效**: 在监控广角镜头下，手机和香烟的像素占比极低，直接检测几乎无效。
2. **模型局限性**: 用户微调的专用模型仅包含行为类别（Smoke/Phone/Drink），缺乏定位驾驶员的能力。
3. **高误报率**: 简单的物体检测常将背景噪点误识别为抽烟；同时，同一动作常被多个框重复标记。

针对上述挑战，我们实施了以下技术方案：

### 2.1 双模型协同架构 (Dual-Model Architecture)
为了解决专用模型无法定位驾驶员的问题，我们在 `detection.py` 中重构了推理流水线：
- **辅助定位器 (Auxiliary Locator)**: 系统自动加载 `yolov8n` 通用模型，利用其强大的 `person` 类识别能力，在复杂画面中精准定位驾驶员坐标。
- **主模型 (Main Behavior Model)**: 用户的微调模型 `best.pt` 专注于行为分类，不再承担定位任务。

### 2.2 二阶段局部特写增强 (ROI Zoom-in)
我们优化了"两阶段检测"算法，使其适应双模型架构：
1. **智能裁剪**: 获取驾驶员坐标后，算法自动向四周扩大裁剪范围（横向+35%，纵向+30%，向下+50%），确保完整覆盖手部动作区域和仪表盘区域。
2. **微距推理**: 将裁剪出的局部图像送入主模型进行推理。由于输入图像中目标像素占比大幅提升，我们可以安全地将置信度阈值降低至 **0.08**，从而捕获极微小的目标（如指尖的香烟）。

### 2.3 精度控制算法
为了平衡超低阈值带来的召回率与准确率，我们引入了两项后处理技术：
- **非极大值抑制 (NMS)**: 
    - 算法计算重叠框的 **IoU (交并比)**。
    - 当 IoU > 0.45 时，系统判定为重复检测，仅保留置信度最高的框。这彻底消除了"一个动作多个框"的重影现象。
- **动态类别阈值过滤 (Dynamic Class Thresholding)**:
    - **Smoke (抽烟)**: 极易受背景干扰。我们将阈值设定为 **0.80**，只有模型确信无疑时才报警，有效压制了误报。
    - **Drink (喝水)**: 动作特征明显但持续时间短。我们将阈值放宽至 **0.10**，确保不漏掉任何瞬间动作。
    - **Phone (手机)**: 保持 **0.25** 的平衡阈值。

---

## 3. YOLOv8n 模型微调与优化

### 3.1 基础模型选择
我们沿用了 **YOLOv8n** 作为基础网络架构，兼顾了边缘计算设备的性能需求。

### 3.2 训练策略
- **Mosaic 4x**: 拼接图像增强对多尺度目标的适应性。
- **MixUp & Copy-Paste**: 增加背景复杂度和目标多样性。
- **HSV 变换**: 强化模型对光照变化的鲁棒性，适应车内阴暗环境。

---

## 4. 系统架构与实现

### 4.1 技术栈
- **后端**: FastAPI (Python 3.9+)
- **AI 引擎**: Ultralytics YOLOv8 (Detector + Classifier)
- **视觉处理**: OpenCV, NumPy (NMS算法实现)
- **前端**: HTML5, Vanilla JavaScript, Canvas API (Dashboard UI)

### 4.2 模块设计
系统采用了高度解耦的设计：
- **检测层**: `DetectionEngine` 类封装了双模型加载逻辑、坐标映射还原算法以及 NMS 后处理。
- **服务层**: 基于 FastAPI 的异步接口，支持视频流的实时切片与分析。
- **展示层**: 全新的 "Cockpit" 驾驶舱风格 UI，提供实时的遥测数据（Telemetry Data）展示和可视化的扫描线反馈。

---

## 5. 实验分析与结论

通过引入辅助定位与 NMS 算法，系统在路口监控样本上的表现有了质的飞跃：
- **漏报率**: 降低了约 **85%**。此前无法识别的远距离抽烟动作现在能精准捕获。
- **误报率**: 降低了约 **90%**。通过将 Smoke 阈值提升至 0.8，彻底消除了将喝水动作误判为抽烟的情况。
- **稳定性**: NMS 算法消除了检测框抖动和重叠，输出画面更加稳定、专业。

本系统成功证明了"通用模型定位 + 专用模型识别"的技术路线在复杂场景下的优越性，不仅解决了单一模型的局限，更为未来的多任务扩展奠定了基础。
