# ç›®æ ‡æ£€æµ‹ä»»åŠ¡(æ¨¡å¼è¯†åˆ«æ–¹æ³•åœ¨é©¾é©¶å‘˜è¡Œä¸ºç›®æ ‡æ£€æµ‹ä¸Šçš„åº”ç”¨)

## ä¸€ã€é¡¹ç›®æ¦‚è¿°

### 1.1 é¡¹ç›®èƒŒæ™¯
æœ¬é¡¹ç›®æ—¨åœ¨å¼€å‘ä¸€ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„é©¾é©¶å‘˜è¡Œä¸ºæ£€æµ‹ç³»ç»Ÿ,ç”¨äºè¯†åˆ«é©¾é©¶è¿‡ç¨‹ä¸­çš„å±é™©è¡Œä¸º,åŒ…æ‹¬æŠ½çƒŸ(Smoke)ã€ä½¿ç”¨æ‰‹æœº(Phone)å’Œå–æ°´(Drink)ä¸‰ç§è¡Œä¸ºã€‚è¿™å¯¹äºæé«˜é“è·¯å®‰å…¨ã€è¾…åŠ©è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿå…·æœ‰é‡è¦æ„ä¹‰ã€‚

### 1.2 é¡¹ç›®ç›®æ ‡
- ä½¿ç”¨YOLOv8nä½œä¸ºåŸºç¡€æ¨¡å‹
- åœ¨æä¾›çš„æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒå’Œä¼˜åŒ–
- è¾¾åˆ°æˆ–è¶…è¿‡åŸºçº¿ç»“æœ(mAP@0.5: 0.94152, mAP@0.5:0.95: 0.65009)
- æ¢ç´¢å¤šç§ä¼˜åŒ–ç­–ç•¥æå‡æ¨¡å‹æ€§èƒ½

### 1.3 æ•°æ®é›†ä¿¡æ¯
- **è®­ç»ƒé›†**: 7981å¼ å›¾åƒ
- **éªŒè¯é›†**: 997å¼ å›¾åƒ  
- **æµ‹è¯•é›†**: 997å¼ å›¾åƒ
- **ç±»åˆ«æ•°**: 3ç±»(Smoke, Phone, Drink)
- **æ•°æ®æ ¼å¼**: YOLOv8æ ¼å¼
- **æ•°æ®å¤§å°**: çº¦350MB

### 1.4 è¯„ä»·æŒ‡æ ‡
- Average Precision (AP)
- Recall
- mAP@0.5
- mAP@0.5:0.95

---

## äºŒã€æŠ€æœ¯æ–¹æ¡ˆ

### 2.1 YOLOv8næ¶æ„ç®€ä»‹
YOLOv8æ˜¯YOLOç³»åˆ—çš„æœ€æ–°ç‰ˆæœ¬,å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹:
- **Backbone**: CSPDarknet with C2f modules
- **Neck**: PAN-FPN (Path Aggregation Network - Feature Pyramid Network)
- **Head**: Decoupled head (åˆ†ç¦»åˆ†ç±»å’Œå›å½’ä»»åŠ¡)
- **Anchor-free**: æ— é”šæ¡†è®¾è®¡,ç®€åŒ–è®­ç»ƒè¿‡ç¨‹

YOLOv8næ˜¯æœ€è½»é‡çº§çš„ç‰ˆæœ¬,å‚æ•°é‡çº¦3.2M,é€‚åˆå¿«é€Ÿè¿­ä»£å’Œå®éªŒã€‚

### 2.2 ä¼˜åŒ–ç­–ç•¥

#### 2.2.1 æ•°æ®å¢å¼ºç­–ç•¥
- **Mosaicå¢å¼º**: æ‹¼æ¥4å¼ å›¾åƒ,å¢åŠ å°ç›®æ ‡æ£€æµ‹èƒ½åŠ›
- **MixUp**: æ··åˆä¸¤å¼ å›¾åƒ,æé«˜æ³›åŒ–èƒ½åŠ›
- **éšæœºæ—‹è½¬ã€ç¿»è½¬**: å¢åŠ æ•°æ®å¤šæ ·æ€§
- **é¢œè‰²å˜æ¢**: HSVè‰²å½©ç©ºé—´å˜æ¢
- **éšæœºç¼©æ”¾å’Œè£å‰ª**: é€‚åº”ä¸åŒå°ºåº¦çš„ç›®æ ‡

#### 2.2.2 æ¨¡å‹ä¼˜åŒ–æ–¹å‘
1. **è¶…å‚æ•°è°ƒä¼˜**
   - å­¦ä¹ ç‡è°ƒæ•´
   - Batch sizeä¼˜åŒ–
   - ä¼˜åŒ–å™¨é€‰æ‹©(Adam/SGD/AdamW)
   - æƒé‡è¡°å‡è°ƒæ•´

2. **æŸå¤±å‡½æ•°ä¼˜åŒ–**
   - åˆ†ç±»æŸå¤±: BCE Loss
   - è¾¹ç•Œæ¡†å›å½’æŸå¤±: CIoU Loss
   - æŸå¤±æƒé‡å¹³è¡¡

3. **ç½‘ç»œç»“æ„è°ƒæ•´**
   - å¢åŠ /å‡å°‘æ£€æµ‹å¤´
   - è°ƒæ•´ç‰¹å¾é‡‘å­—å¡”å±‚æ•°
   - å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶(CBAM, SE, ECAç­‰)

4. **è®­ç»ƒæŠ€å·§**
   - Warm-upç­–ç•¥
   - Cosineé€€ç«å­¦ä¹ ç‡
   - EMA(æŒ‡æ•°ç§»åŠ¨å¹³å‡)
   - å¤šå°ºåº¦è®­ç»ƒ

---

## ä¸‰ã€ç¯å¢ƒé…ç½®

### 3.1 ç¡¬ä»¶è¦æ±‚
- **æ¨èé…ç½®**: NVIDIA GPU (8GB+ æ˜¾å­˜)
- **æœ€ä½é…ç½®**: CPU (è®­ç»ƒé€Ÿåº¦è¾ƒæ…¢)
- **å‚è€ƒé…ç½®**: GTX 1080Ti (11GB) - 150 epochsçº¦3å°æ—¶

### 3.2 è½¯ä»¶ç¯å¢ƒ

```bash
# Pythonç‰ˆæœ¬: 3.8+
python --version

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n yolov8_driver python=3.9
conda activate yolov8_driver

# å®‰è£…PyTorch (æ ¹æ®CUDAç‰ˆæœ¬é€‰æ‹©)
# CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# æˆ– CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# å®‰è£…Ultralytics (YOLOv8å®˜æ–¹åŒ…)
pip install ultralytics

# å…¶ä»–ä¾èµ–
pip install opencv-python matplotlib pandas seaborn scikit-learn tensorboard
```

### 3.3 éªŒè¯å®‰è£…

```python
# test_env.py
import torch
import ultralytics
from ultralytics import YOLO

print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDA version: {torch.version.cuda}")
    print(f"GPU: {torch.cuda.get_device_name(0)}")
print(f"Ultralytics version: {ultralytics.__version__}")
```

---

## å››ã€æ•°æ®é›†å‡†å¤‡

### 4.1 ä¸‹è½½æ•°æ®é›†
```bash
# ä»ç™¾åº¦ç½‘ç›˜ä¸‹è½½ datasets_3.zip
# é“¾æ¥: https://pan.baidu.com/s/1ImSeem7Cg9-2zvTa4AF7CA?pwd=tfib
# æå–ç : tfib
```

### 4.2 æ•°æ®é›†ç»“æ„
```
datasets_3/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ img001.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ labels/
â”‚       â”œâ”€â”€ img001.txt
â”‚       â””â”€â”€ ...
â”œâ”€â”€ valid/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â””â”€â”€ data.yaml
```

### 4.3 åˆ›å»ºdata.yamlé…ç½®æ–‡ä»¶
```yaml
# data.yaml
path: /path/to/datasets_3  # æ•°æ®é›†æ ¹ç›®å½•
train: train/images  # è®­ç»ƒé›†è·¯å¾„
val: valid/images    # éªŒè¯é›†è·¯å¾„
test: test/images    # æµ‹è¯•é›†è·¯å¾„

# ç±»åˆ«
nc: 3  # ç±»åˆ«æ•°é‡
names: ['Smoke', 'Phone', 'Drink']  # ç±»åˆ«åç§°
```

### 4.4 æ•°æ®æ¢ç´¢ä¸åˆ†æ

```python
# data_analysis.py
import os
from pathlib import Path
import matplotlib.pyplot as plt
import numpy as np

def analyze_dataset(labels_dir):
    """åˆ†ææ•°æ®é›†æ ‡ç­¾åˆ†å¸ƒ"""
    class_counts = {0: 0, 1: 0, 2: 0}  # Smoke, Phone, Drink
    bbox_sizes = []
    
    for label_file in Path(labels_dir).glob('*.txt'):
        with open(label_file, 'r') as f:
            for line in f:
                cls, x, y, w, h = map(float, line.strip().split())
                class_counts[int(cls)] += 1
                bbox_sizes.append((w, h))
    
    # å¯è§†åŒ–ç±»åˆ«åˆ†å¸ƒ
    plt.figure(figsize=(12, 4))
    
    plt.subplot(1, 3, 1)
    plt.bar(['Smoke', 'Phone', 'Drink'], class_counts.values())
    plt.title('Class Distribution')
    plt.ylabel('Count')
    
    # å¯è§†åŒ–è¾¹ç•Œæ¡†å¤§å°åˆ†å¸ƒ
    bbox_sizes = np.array(bbox_sizes)
    plt.subplot(1, 3, 2)
    plt.scatter(bbox_sizes[:, 0], bbox_sizes[:, 1], alpha=0.5)
    plt.xlabel('Width')
    plt.ylabel('Height')
    plt.title('Bounding Box Size Distribution')
    
    # é¢ç§¯åˆ†å¸ƒ
    plt.subplot(1, 3, 3)
    areas = bbox_sizes[:, 0] * bbox_sizes[:, 1]
    plt.hist(areas, bins=50)
    plt.xlabel('Area')
    plt.ylabel('Count')
    plt.title('Bounding Box Area Distribution')
    
    plt.tight_layout()
    plt.savefig('dataset_analysis.png')
    print(f"Class counts: {class_counts}")
    print(f"Average bbox size: {bbox_sizes.mean(axis=0)}")

# ä½¿ç”¨ç¤ºä¾‹
analyze_dataset('datasets_3/train/labels')
```

---

## äº”ã€æ¨¡å‹è®­ç»ƒ

### 5.1 åŸºç¡€è®­ç»ƒè„šæœ¬

```python
# train_baseline.py
from ultralytics import YOLO
import torch

def train_baseline():
    """åŸºç¡€è®­ç»ƒ,å¤ç°baselineç»“æœ"""
    
    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    model = YOLO('yolov8n.pt')
    
    # è®­ç»ƒå‚æ•°
    results = model.train(
        data='datasets_3/data.yaml',      # æ•°æ®é…ç½®æ–‡ä»¶
        epochs=150,                        # è®­ç»ƒè½®æ•°
        imgsz=640,                         # å›¾åƒå°ºå¯¸
        batch=16,                          # batch size
        device=0,                          # GPUè®¾å¤‡
        workers=8,                         # æ•°æ®åŠ è½½çº¿ç¨‹æ•°
        
        # ä¼˜åŒ–å™¨å‚æ•°
        optimizer='SGD',                   # ä¼˜åŒ–å™¨
        lr0=0.01,                          # åˆå§‹å­¦ä¹ ç‡
        lrf=0.01,                          # æœ€ç»ˆå­¦ä¹ ç‡å› å­
        momentum=0.937,                    # SGD momentum
        weight_decay=0.0005,               # æƒé‡è¡°å‡
        
        # æ•°æ®å¢å¼º
        hsv_h=0.015,                       # è‰²è°ƒå¢å¼º
        hsv_s=0.7,                         # é¥±å’Œåº¦å¢å¼º
        hsv_v=0.4,                         # äº®åº¦å¢å¼º
        degrees=0.0,                       # æ—‹è½¬è§’åº¦
        translate=0.1,                     # å¹³ç§»
        scale=0.5,                         # ç¼©æ”¾
        shear=0.0,                         # å‰ªåˆ‡
        perspective=0.0,                   # é€è§†
        flipud=0.0,                        # ä¸Šä¸‹ç¿»è½¬æ¦‚ç‡
        fliplr=0.5,                        # å·¦å³ç¿»è½¬æ¦‚ç‡
        mosaic=1.0,                        # Mosaicå¢å¼ºæ¦‚ç‡
        mixup=0.0,                         # MixUpå¢å¼ºæ¦‚ç‡
        
        # å…¶ä»–è®¾ç½®
        patience=50,                       # æ—©åœpatience
        save=True,                         # ä¿å­˜æ£€æŸ¥ç‚¹
        save_period=-1,                    # ä¿å­˜å‘¨æœŸ(-1è¡¨ç¤ºåªä¿å­˜æœ€ä½³)
        cache=False,                       # æ˜¯å¦ç¼“å­˜å›¾åƒåˆ°å†…å­˜
        project='runs/detect',             # é¡¹ç›®ç›®å½•
        name='baseline_yolov8n',           # å®éªŒåç§°
        exist_ok=False,                    # æ˜¯å¦è¦†ç›–å·²æœ‰å®éªŒ
        pretrained=True,                   # ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
        verbose=True,                      # è¯¦ç»†è¾“å‡º
        seed=0,                            # éšæœºç§å­
        deterministic=True,                # ç¡®å®šæ€§è®­ç»ƒ
    )
    
    return results

if __name__ == '__main__':
    results = train_baseline()
    print("Training completed!")
    print(f"Best mAP50: {results.results_dict['metrics/mAP50(B)']}")
    print(f"Best mAP50-95: {results.results_dict['metrics/mAP50-95(B)']}")
```

### 5.2 ä¼˜åŒ–è®­ç»ƒè„šæœ¬

```python
# train_optimized.py
from ultralytics import YOLO
import torch

def train_optimized():
    """ä¼˜åŒ–è®­ç»ƒç­–ç•¥"""
    
    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    model = YOLO('yolov8n.pt')
    
    # ä¼˜åŒ–åçš„è®­ç»ƒå‚æ•°
    results = model.train(
        data='datasets_3/data.yaml',
        epochs=200,                        # å¢åŠ è®­ç»ƒè½®æ•°
        imgsz=640,
        batch=32,                          # å¢å¤§batch size(å¦‚æœæ˜¾å­˜å…è®¸)
        device=0,
        workers=8,
        
        # ä¼˜åŒ–å™¨å‚æ•°è°ƒæ•´
        optimizer='AdamW',                 # ä½¿ç”¨AdamWä¼˜åŒ–å™¨
        lr0=0.001,                         # é™ä½åˆå§‹å­¦ä¹ ç‡
        lrf=0.01,
        weight_decay=0.0005,
        
        # å¢å¼ºæ•°æ®å¢å¼º
        hsv_h=0.015,
        hsv_s=0.7,
        hsv_v=0.4,
        degrees=10.0,                      # å¢åŠ æ—‹è½¬
        translate=0.2,                     # å¢åŠ å¹³ç§»
        scale=0.9,                         # å¢åŠ ç¼©æ”¾
        shear=2.0,                         # å¢åŠ å‰ªåˆ‡
        perspective=0.0001,                # å¢åŠ é€è§†å˜æ¢
        flipud=0.0,
        fliplr=0.5,
        mosaic=1.0,
        mixup=0.1,                         # æ·»åŠ MixUp
        copy_paste=0.1,                    # æ·»åŠ Copy-Pasteå¢å¼º
        
        # è®­ç»ƒæŠ€å·§
        cos_lr=True,                       # ä½¿ç”¨ä½™å¼¦é€€ç«å­¦ä¹ ç‡
        warmup_epochs=3.0,                 # Warm-upè½®æ•°
        warmup_momentum=0.8,               # Warm-up momentum
        warmup_bias_lr=0.1,                # Warm-up biaså­¦ä¹ ç‡
        
        # æŸå¤±å‡½æ•°æƒé‡
        box=7.5,                           # box lossæƒé‡
        cls=0.5,                           # cls lossæƒé‡
        dfl=1.5,                           # dfl lossæƒé‡
        
        # å…¶ä»–è®¾ç½®
        patience=100,
        save=True,
        cache=True,                        # ç¼“å­˜å›¾åƒ(å¦‚æœå†…å­˜è¶³å¤Ÿ)
        project='runs/detect',
        name='optimized_yolov8n',
        exist_ok=False,
        pretrained=True,
        verbose=True,
        seed=42,
        deterministic=True,
        
        # å¤šå°ºåº¦è®­ç»ƒ
        multi_scale=True,                  # å¯ç”¨å¤šå°ºåº¦è®­ç»ƒ
    )
    
    return results

if __name__ == '__main__':
    results = train_optimized()
```

### 5.3 è®­ç»ƒç›‘æ§

```python
# monitor_training.py
import os
from pathlib import Path
import matplotlib.pyplot as plt
import pandas as pd

def plot_training_results(results_csv):
    """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
    df = pd.read_csv(results_csv)
    df.columns = df.columns.str.strip()  # å»é™¤ç©ºæ ¼
    
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    
    # mAP@0.5
    axes[0, 0].plot(df['epoch'], df['metrics/mAP50(B)'])
    axes[0, 0].set_title('mAP@0.5')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].grid(True)
    
    # mAP@0.5:0.95
    axes[0, 1].plot(df['epoch'], df['metrics/mAP50-95(B)'])
    axes[0, 1].set_title('mAP@0.5:0.95')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].grid(True)
    
    # Precision
    axes[0, 2].plot(df['epoch'], df['metrics/precision(B)'])
    axes[0, 2].set_title('Precision')
    axes[0, 2].set_xlabel('Epoch')
    axes[0, 2].grid(True)
    
    # Recall
    axes[1, 0].plot(df['epoch'], df['metrics/recall(B)'])
    axes[1, 0].set_title('Recall')
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].grid(True)
    
    # Box Loss
    axes[1, 1].plot(df['epoch'], df['train/box_loss'], label='train')
    axes[1, 1].plot(df['epoch'], df['val/box_loss'], label='val')
    axes[1, 1].set_title('Box Loss')
    axes[1, 1].set_xlabel('Epoch')
    axes[1, 1].legend()
    axes[1, 1].grid(True)
    
    # Cls Loss
    axes[1, 2].plot(df['epoch'], df['train/cls_loss'], label='train')
    axes[1, 2].plot(df['epoch'], df['val/cls_loss'], label='val')
    axes[1, 2].set_title('Classification Loss')
    axes[1, 2].set_xlabel('Epoch')
    axes[1, 2].legend()
    axes[1, 2].grid(True)
    
    plt.tight_layout()
    plt.savefig('training_curves.png', dpi=300)
    plt.show()

# ä½¿ç”¨ç¤ºä¾‹
# plot_training_results('runs/detect/baseline_yolov8n/results.csv')
```

---

## å…­ã€æ¨¡å‹è¯„ä¼°

### 6.1 è¯„ä¼°è„šæœ¬

```python
# evaluate.py
from ultralytics import YOLO
import json

def evaluate_model(model_path, data_yaml):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    
    # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    model = YOLO(model_path)
    
    # åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
    metrics = model.val(
        data=data_yaml,
        split='val',
        imgsz=640,
        batch=16,
        conf=0.001,              # ç½®ä¿¡åº¦é˜ˆå€¼
        iou=0.6,                 # NMS IoUé˜ˆå€¼
        device=0,
        plots=True,              # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        save_json=True,          # ä¿å­˜COCOæ ¼å¼ç»“æœ
        save_hybrid=False,
    )
    
    # æ‰“å°ç»“æœ
    print("\n=== Validation Results ===")
    print(f"Precision: {metrics.box.p.mean():.5f}")
    print(f"Recall: {metrics.box.r.mean():.5f}")
    print(f"mAP@0.5: {metrics.box.map50:.5f}")
    print(f"mAP@0.5:0.95: {metrics.box.map:.5f}")
    
    # æ¯ä¸ªç±»åˆ«çš„AP
    print("\n=== Per-Class AP ===")
    class_names = ['Smoke', 'Phone', 'Drink']
    for i, name in enumerate(class_names):
        print(f"{name}: AP@0.5={metrics.box.ap50[i]:.5f}, "
              f"AP@0.5:0.95={metrics.box.ap[i]:.5f}")
    
    return metrics

def test_model(model_path, data_yaml):
    """åœ¨æµ‹è¯•é›†ä¸Šæµ‹è¯•"""
    model = YOLO(model_path)
    
    # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
    metrics = model.val(
        data=data_yaml,
        split='test',
        imgsz=640,
        batch=16,
        conf=0.001,
        iou=0.6,
        device=0,
        plots=True,
        save_json=True,
    )
    
    print("\n=== Test Results ===")
    print(f"Precision: {metrics.box.p.mean():.5f}")
    print(f"Recall: {metrics.box.r.mean():.5f}")
    print(f"mAP@0.5: {metrics.box.map50:.5f}")
    print(f"mAP@0.5:0.95: {metrics.box.map:.5f}")
    
    return metrics

if __name__ == '__main__':
    # è¯„ä¼°æœ€ä½³æ¨¡å‹
    model_path = 'runs/detect/baseline_yolov8n/weights/best.pt'
    data_yaml = 'datasets_3/data.yaml'
    
    # éªŒè¯é›†è¯„ä¼°
    val_metrics = evaluate_model(model_path, data_yaml)
    
    # æµ‹è¯•é›†è¯„ä¼°
    test_metrics = test_model(model_path, data_yaml)
```

### 6.2 å¯è§†åŒ–é¢„æµ‹ç»“æœ

```python
# visualize_predictions.py
from ultralytics import YOLO
import cv2
import matplotlib.pyplot as plt
from pathlib import Path
import random

def visualize_predictions(model_path, image_dir, num_images=9):
    """å¯è§†åŒ–é¢„æµ‹ç»“æœ"""
    model = YOLO(model_path)
    
    # éšæœºé€‰æ‹©å›¾åƒ
    image_files = list(Path(image_dir).glob('*.jpg'))
    selected_images = random.sample(image_files, min(num_images, len(image_files)))
    
    fig, axes = plt.subplots(3, 3, figsize=(15, 15))
    axes = axes.flatten()
    
    for idx, img_path in enumerate(selected_images):
        # é¢„æµ‹
        results = model(img_path, conf=0.25)
        
        # ç»˜åˆ¶ç»“æœ
        img_with_boxes = results[0].plot()
        img_rgb = cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB)
        
        axes[idx].imshow(img_rgb)
        axes[idx].axis('off')
        axes[idx].set_title(f"Image {idx+1}")
    
    plt.tight_layout()
    plt.savefig('prediction_samples.png', dpi=300)
    plt.show()

# ä½¿ç”¨ç¤ºä¾‹
# visualize_predictions('runs/detect/baseline_yolov8n/weights/best.pt', 
#                       'datasets_3/test/images')
```

### 6.3 æ··æ·†çŸ©é˜µåˆ†æ

```python
# confusion_matrix_analysis.py
from ultralytics import YOLO
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

def plot_confusion_matrix(model_path, data_yaml):
    """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
    model = YOLO(model_path)
    
    # éªŒè¯å¹¶ç”Ÿæˆæ··æ·†çŸ©é˜µ
    metrics = model.val(data=data_yaml, plots=True)
    
    # æ··æ·†çŸ©é˜µå·²ç»åœ¨éªŒè¯è¿‡ç¨‹ä¸­ç”Ÿæˆ
    # ä½äº runs/detect/[name]/confusion_matrix.png
    
    print("Confusion matrix saved in the validation results directory")

# ä½¿ç”¨ç¤ºä¾‹
# plot_confusion_matrix('runs/detect/baseline_yolov8n/weights/best.pt',
#                       'datasets_3/data.yaml')
```

---

## ä¸ƒã€é«˜çº§ä¼˜åŒ–æŠ€å·§

### 7.1 æ³¨æ„åŠ›æœºåˆ¶é›†æˆ

```python
# attention_yolov8.py
"""
æ³¨æ„åŠ›æœºåˆ¶é›†æˆç¤ºä¾‹
æ³¨æ„: éœ€è¦ä¿®æ”¹ultralyticsæºç æˆ–åˆ›å»ºè‡ªå®šä¹‰æ¨¡å‹
"""

# ç¤ºä¾‹: CBAMæ³¨æ„åŠ›æ¨¡å—
import torch
import torch.nn as nn

class ChannelAttention(nn.Module):
    def __init__(self, in_channels, reduction=16):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
        self.fc = nn.Sequential(
            nn.Conv2d(in_channels, in_channels // reduction, 1, bias=False),
            nn.ReLU(),
            nn.Conv2d(in_channels // reduction, in_channels, 1, bias=False)
        )
        self.sigmoid = nn.Sigmoid()
    
    def forward(self, x):
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        out = self.sigmoid(avg_out + max_out)
        return x * out

class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super().__init__()
        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
        self.sigmoid = nn.Sigmoid()
    
    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        out = torch.cat([avg_out, max_out], dim=1)
        out = self.sigmoid(self.conv(out))
        return x * out

class CBAM(nn.Module):
    def __init__(self, in_channels, reduction=16, kernel_size=7):
        super().__init__()
        self.ca = ChannelAttention(in_channels, reduction)
        self.sa = SpatialAttention(kernel_size)
    
    def forward(self, x):
        x = self.ca(x)
        x = self.sa(x)
        return x
```

### 7.2 çŸ¥è¯†è’¸é¦

```python
# knowledge_distillation.py
"""
ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹(å¦‚YOLOv8m)ä½œä¸ºæ•™å¸ˆæ¨¡å‹,
è’¸é¦åˆ°YOLOv8nå­¦ç”Ÿæ¨¡å‹
"""

import torch
import torch.nn as nn
from ultralytics import YOLO

class DistillationLoss(nn.Module):
    def __init__(self, alpha=0.5, temperature=4.0):
        super().__init__()
        self.alpha = alpha
        self.temperature = temperature
        self.kl_div = nn.KLDivLoss(reduction='batchmean')
    
    def forward(self, student_logits, teacher_logits, true_labels):
        # è½¯æ ‡ç­¾æŸå¤±
        soft_loss = self.kl_div(
            torch.log_softmax(student_logits / self.temperature, dim=1),
            torch.softmax(teacher_logits / self.temperature, dim=1)
        ) * (self.temperature ** 2)
        
        # ç¡¬æ ‡ç­¾æŸå¤±
        hard_loss = nn.CrossEntropyLoss()(student_logits, true_labels)
        
        # ç»„åˆæŸå¤±
        return self.alpha * soft_loss + (1 - self.alpha) * hard_loss

# æ³¨æ„: YOLOv8çš„çŸ¥è¯†è’¸é¦éœ€è¦è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯
# è¿™é‡Œæä¾›æ€è·¯,å…·ä½“å®ç°è¾ƒå¤æ‚
```

### 7.3 è¶…å‚æ•°æœç´¢

```python
# hyperparameter_tuning.py
from ultralytics import YOLO
import optuna

def objective(trial):
    """Optunaè¶…å‚æ•°ä¼˜åŒ–ç›®æ ‡å‡½æ•°"""
    
    # å®šä¹‰è¶…å‚æ•°æœç´¢ç©ºé—´
    lr0 = trial.suggest_float('lr0', 1e-4, 1e-2, log=True)
    lrf = trial.suggest_float('lrf', 0.01, 0.1)
    momentum = trial.suggest_float('momentum', 0.8, 0.95)
    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)
    batch = trial.suggest_categorical('batch', [8, 16, 32])
    
    # è®­ç»ƒæ¨¡å‹
    model = YOLO('yolov8n.pt')
    results = model.train(
        data='datasets_3/data.yaml',
        epochs=50,  # å‡å°‘epochä»¥åŠ å¿«æœç´¢
        imgsz=640,
        batch=batch,
        lr0=lr0,
        lrf=lrf,
        momentum=momentum,
        weight_decay=weight_decay,
        device=0,
        project='runs/tuning',
        name=f'trial_{trial.number}',
        exist_ok=True,
        verbose=False,
    )
    
    # è¿”å›ä¼˜åŒ–ç›®æ ‡ (mAP@0.5:0.95)
    return results.results_dict['metrics/mAP50-95(B)']

def run_hyperparameter_search(n_trials=20):
    """è¿è¡Œè¶…å‚æ•°æœç´¢"""
    study = optuna.create_study(direction='maximize')
    study.optimize(objective, n_trials=n_trials)
    
    print("\n=== Best Hyperparameters ===")
    print(study.best_params)
    print(f"Best mAP50-95: {study.best_value:.5f}")
    
    # å¯è§†åŒ–ä¼˜åŒ–å†å²
    from optuna.visualization import plot_optimization_history, plot_param_importances
    
    fig1 = plot_optimization_history(study)
    fig1.write_html('optimization_history.html')
    
    fig2 = plot_param_importances(study)
    fig2.write_html('param_importances.html')

# ä½¿ç”¨ç¤ºä¾‹
# run_hyperparameter_search(n_trials=20)
```

### 7.4 æ¨¡å‹é›†æˆ

```python
# ensemble.py
from ultralytics import YOLO
import torch
import numpy as np

class YOLOEnsemble:
    """YOLOæ¨¡å‹é›†æˆ"""
    
    def __init__(self, model_paths, weights=None):
        self.models = [YOLO(path) for path in model_paths]
        self.weights = weights if weights else [1.0] * len(model_paths)
        self.weights = np.array(self.weights) / sum(self.weights)
    
    def predict(self, image, conf=0.25, iou=0.45):
        """é›†æˆé¢„æµ‹"""
        all_boxes = []
        all_scores = []
        all_classes = []
        
        # æ”¶é›†æ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹
        for model, weight in zip(self.models, self.weights):
            results = model(image, conf=conf, verbose=False)[0]
            boxes = results.boxes.xyxy.cpu().numpy()
            scores = results.boxes.conf.cpu().numpy() * weight
            classes = results.boxes.cls.cpu().numpy()
            
            all_boxes.append(boxes)
            all_scores.append(scores)
            all_classes.append(classes)
        
        # åˆå¹¶é¢„æµ‹
        if len(all_boxes) > 0:
            all_boxes = np.concatenate(all_boxes)
            all_scores = np.concatenate(all_scores)
            all_classes = np.concatenate(all_classes)
            
            # æ‰§è¡ŒNMS
            keep_indices = self._nms(all_boxes, all_scores, iou)
            
            return {
                'boxes': all_boxes[keep_indices],
                'scores': all_scores[keep_indices],
                'classes': all_classes[keep_indices]
            }
        
        return {'boxes': [], 'scores': [], 'classes': []}
    
    def _nms(self, boxes, scores, iou_threshold):
        """éæå¤§å€¼æŠ‘åˆ¶"""
        x1 = boxes[:, 0]
        y1 = boxes[:, 1]
        x2 = boxes[:, 2]
        y2 = boxes[:, 3]
        
        areas = (x2 - x1) * (y2 - y1)
        order = scores.argsort()[::-1]
        
        keep = []
        while order.size > 0:
            i = order[0]
            keep.append(i)
            
            xx1 = np.maximum(x1[i], x1[order[1:]])
            yy1 = np.maximum(y1[i], y1[order[1:]])
            xx2 = np.minimum(x2[i], x2[order[1:]])
            yy2 = np.minimum(y2[i], y2[order[1:]])
            
            w = np.maximum(0.0, xx2 - xx1)
            h = np.maximum(0.0, yy2 - yy1)
            inter = w * h
            
            iou = inter / (areas[i] + areas[order[1:]] - inter)
            
            inds = np.where(iou <= iou_threshold)[0]
            order = order[inds + 1]
        
        return keep

# ä½¿ç”¨ç¤ºä¾‹
# ensemble = YOLOEnsemble([
#     'runs/detect/exp1/weights/best.pt',
#     'runs/detect/exp2/weights/best.pt',
#     'runs/detect/exp3/weights/best.pt'
# ], weights=[1.0, 1.0, 1.0])
# 
# results = ensemble.predict('test_image.jpg')
```

---

## å…«ã€å®éªŒè®¾è®¡ä¸å¯¹æ¯”

### 8.1 å®éªŒæ–¹æ¡ˆ

| å®éªŒç¼–å· | å®éªŒåç§° | ä¸»è¦æ”¹è¿› | é¢„æœŸæ•ˆæœ |
|---------|---------|---------|---------|
| Exp-1 | Baseline | YOLOv8né»˜è®¤å‚æ•° | å»ºç«‹åŸºçº¿ |
| Exp-2 | Data Augmentation | å¢å¼ºæ•°æ®å¢å¼º(MixUp, Copy-Paste) | æå‡æ³›åŒ–èƒ½åŠ› |
| Exp-3 | Optimizer Tuning | ä½¿ç”¨AdamWä¼˜åŒ–å™¨ | åŠ å¿«æ”¶æ•› |
| Exp-4 | Learning Rate | è°ƒæ•´å­¦ä¹ ç‡ç­–ç•¥ | æ›´å¥½çš„æ”¶æ•› |
| Exp-5 | Multi-Scale Training | å¤šå°ºåº¦è®­ç»ƒ | æå‡ä¸åŒå°ºåº¦ç›®æ ‡æ£€æµ‹ |
| Exp-6 | Loss Weight Tuning | è°ƒæ•´æŸå¤±å‡½æ•°æƒé‡ | å¹³è¡¡å„é¡¹æŸå¤± |
| Exp-7 | Model Ensemble | 3ä¸ªæ¨¡å‹é›†æˆ | æå‡æ•´ä½“æ€§èƒ½ |

### 8.2 å®éªŒè®°å½•æ¨¡æ¿

```python
# experiment_log.py
import json
from datetime import datetime

class ExperimentLogger:
    """å®éªŒæ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self, log_file='experiments.json'):
        self.log_file = log_file
        self.experiments = self._load_logs()
    
    def _load_logs(self):
        try:
            with open(self.log_file, 'r') as f:
                return json.load(f)
        except FileNotFoundError:
            return []
    
    def log_experiment(self, exp_name, config, results):
        """è®°å½•å®éªŒ"""
        experiment = {
            'name': exp_name,
            'timestamp': datetime.now().isoformat(),
            'config': config,
            'results': results
        }
        self.experiments.append(experiment)
        self._save_logs()
    
    def _save_logs(self):
        with open(self.log_file, 'w') as f:
            json.dump(self.experiments, f, indent=2)
    
    def get_best_experiment(self, metric='mAP50-95'):
        """è·å–æœ€ä½³å®éªŒ"""
        if not self.experiments:
            return None
        return max(self.experiments, 
                   key=lambda x: x['results'].get(metric, 0))

# ä½¿ç”¨ç¤ºä¾‹
# logger = ExperimentLogger()
# logger.log_experiment(
#     exp_name='baseline',
#     config={'lr0': 0.01, 'epochs': 150, 'batch': 16},
#     results={'mAP50': 0.94152, 'mAP50-95': 0.65009}
# )
```

---

## ä¹ã€æ¨¡å‹éƒ¨ç½²

### 9.1 å¯¼å‡ºæ¨¡å‹

```python
# export_model.py
from ultralytics import YOLO

def export_to_onnx(model_path, imgsz=640):
    """å¯¼å‡ºä¸ºONNXæ ¼å¼"""
    model = YOLO(model_path)
    model.export(format='onnx', imgsz=imgsz, simplify=True)
    print(f"Model exported to ONNX format")

def export_to_tensorrt(model_path, imgsz=640):
    """å¯¼å‡ºä¸ºTensorRTæ ¼å¼(éœ€è¦TensorRTç¯å¢ƒ)"""
    model = YOLO(model_path)
    model.export(format='engine', imgsz=imgsz, half=True)
    print(f"Model exported to TensorRT format")

def export_to_coreml(model_path, imgsz=640):
    """å¯¼å‡ºä¸ºCoreMLæ ¼å¼(iOSéƒ¨ç½²)"""
    model = YOLO(model_path)
    model.export(format='coreml', imgsz=imgsz)
    print(f"Model exported to CoreML format")

# ä½¿ç”¨ç¤ºä¾‹
# export_to_onnx('runs/detect/baseline_yolov8n/weights/best.pt')
```

### 9.2 æ¨ç†è„šæœ¬

```python
# inference.py
from ultralytics import YOLO
import cv2
import time

class DriverBehaviorDetector:
    """é©¾é©¶å‘˜è¡Œä¸ºæ£€æµ‹å™¨"""
    
    def __init__(self, model_path, conf_threshold=0.25):
        self.model = YOLO(model_path)
        self.conf_threshold = conf_threshold
        self.class_names = ['Smoke', 'Phone', 'Drink']
        self.colors = {
            0: (0, 0, 255),    # Smoke - çº¢è‰²
            1: (255, 0, 0),    # Phone - è“è‰²
            2: (0, 255, 0)     # Drink - ç»¿è‰²
        }
    
    def detect_image(self, image_path, save_path=None):
        """æ£€æµ‹å•å¼ å›¾åƒ"""
        results = self.model(image_path, conf=self.conf_threshold)[0]
        
        # ç»˜åˆ¶ç»“æœ
        img = cv2.imread(image_path)
        for box in results.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            conf = float(box.conf[0])
            cls = int(box.cls[0])
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            color = self.colors[cls]
            cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)
            
            # ç»˜åˆ¶æ ‡ç­¾
            label = f"{self.class_names[cls]}: {conf:.2f}"
            cv2.putText(img, label, (x1, y1-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        if save_path:
            cv2.imwrite(save_path, img)
        
        return img, results
    
    def detect_video(self, video_path, output_path=None):
        """æ£€æµ‹è§†é¢‘"""
        cap = cv2.VideoCapture(video_path)
        
        # è·å–è§†é¢‘å±æ€§
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
        if output_path:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        frame_count = 0
        total_time = 0
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            # æ£€æµ‹
            start_time = time.time()
            results = self.model(frame, conf=self.conf_threshold)[0]
            inference_time = time.time() - start_time
            total_time += inference_time
            frame_count += 1
            
            # ç»˜åˆ¶ç»“æœ
            for box in results.boxes:
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                conf = float(box.conf[0])
                cls = int(box.cls[0])
                
                color = self.colors[cls]
                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                label = f"{self.class_names[cls]}: {conf:.2f}"
                cv2.putText(frame, label, (x1, y1-10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
            
            # æ˜¾ç¤ºFPS
            fps_text = f"FPS: {1/inference_time:.1f}"
            cv2.putText(frame, fps_text, (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            
            if output_path:
                out.write(frame)
            
            cv2.imshow('Driver Behavior Detection', frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        avg_fps = frame_count / total_time if total_time > 0 else 0
        print(f"Average FPS: {avg_fps:.2f}")
        
        cap.release()
        if output_path:
            out.release()
        cv2.destroyAllWindows()
    
    def detect_webcam(self):
        """å®æ—¶æ£€æµ‹æ‘„åƒå¤´"""
        self.detect_video(0)

# ä½¿ç”¨ç¤ºä¾‹
# detector = DriverBehaviorDetector('runs/detect/baseline_yolov8n/weights/best.pt')
# detector.detect_image('test.jpg', 'result.jpg')
# detector.detect_video('test_video.mp4', 'output_video.mp4')
# detector.detect_webcam()
```

---

## åã€é¡¹ç›®æ€»ç»“ä¸æ”¹è¿›æ–¹å‘

### 10.1 é¡¹ç›®æ£€æŸ¥æ¸…å•

- [ ] ç¯å¢ƒé…ç½®å®Œæˆ
- [ ] æ•°æ®é›†ä¸‹è½½å¹¶è§£å‹
- [ ] æ•°æ®é›†ç»“æ„éªŒè¯
- [ ] æ•°æ®åˆ†æå®Œæˆ
- [ ] Baselineè®­ç»ƒå®Œæˆ
- [ ] è®­ç»ƒæ›²çº¿åˆ†æ
- [ ] ä¼˜åŒ–å®éªŒè®¾è®¡
- [ ] å¤šç»„å¯¹æ¯”å®éªŒ
- [ ] æ¨¡å‹è¯„ä¼°(éªŒè¯é›†)
- [ ] æ¨¡å‹è¯„ä¼°(æµ‹è¯•é›†)
- [ ] ç»“æœå¯è§†åŒ–
- [ ] æ··æ·†çŸ©é˜µåˆ†æ
- [ ] æ¨¡å‹å¯¼å‡º
- [ ] æ¨ç†è„šæœ¬æµ‹è¯•
- [ ] å®éªŒæŠ¥å‘Šæ’°å†™

### 10.2 å¯èƒ½çš„æ”¹è¿›æ–¹å‘

#### 10.2.1 æ•°æ®å±‚é¢
1. **æ•°æ®å¢å¼º**
   - å°è¯•AutoAugmentã€RandAugment
   - ä½¿ç”¨YOLO-Augmentç­–ç•¥
   - æ·»åŠ ç‰¹å®šåœºæ™¯çš„å¢å¼º(å…‰ç…§å˜åŒ–ã€æ¨¡ç³Šç­‰)

2. **æ•°æ®æ¸…æ´—**
   - æ£€æŸ¥æ ‡æ³¨è´¨é‡
   - ç§»é™¤ä½è´¨é‡æ ·æœ¬
   - å¢åŠ å›°éš¾æ ·æœ¬

3. **æ•°æ®æ‰©å……**
   - æ”¶é›†æ›´å¤šçœŸå®åœºæ™¯æ•°æ®
   - ä½¿ç”¨æ•°æ®ç”ŸæˆæŠ€æœ¯(GAN)

#### 10.2.2 æ¨¡å‹å±‚é¢
1. **æ›´å¤§çš„æ¨¡å‹**
   - å°è¯•YOLOv8s/m/l/x
   - æƒè¡¡é€Ÿåº¦å’Œç²¾åº¦

2. **æ¶æ„æ”¹è¿›**
   - æ·»åŠ æ³¨æ„åŠ›æœºåˆ¶(CBAM, SENet)
   - æ”¹è¿›ç‰¹å¾é‡‘å­—å¡”(BiFPN)
   - ä½¿ç”¨Transformerç»“æ„

3. **æŸå¤±å‡½æ•°**
   - å°è¯•Focal Losså¤„ç†ç±»åˆ«ä¸å¹³è¡¡
   - ä½¿ç”¨æ›´å¥½çš„IoUæŸå¤±(GIoU, DIoU, CIoU)
   - æ·»åŠ è¾…åŠ©æŸå¤±

#### 10.2.3 è®­ç»ƒç­–ç•¥
1. **è¿ç§»å­¦ä¹ **
   - ä½¿ç”¨åœ¨ç›¸å…³ä»»åŠ¡ä¸Šé¢„è®­ç»ƒçš„æ¨¡å‹
   - å¤šé˜¶æ®µè®­ç»ƒç­–ç•¥

2. **çŸ¥è¯†è’¸é¦**
   - å¤§æ¨¡å‹â†’å°æ¨¡å‹çš„çŸ¥è¯†è¿ç§»

3. **é›†æˆå­¦ä¹ **
   - è®­ç»ƒå¤šä¸ªæ¨¡å‹è¿›è¡Œé›†æˆ
   - ä½¿ç”¨ä¸åŒçš„åˆå§‹åŒ–å’Œå¢å¼ºç­–ç•¥

#### 10.2.4 åå¤„ç†ä¼˜åŒ–
1. **NMSä¼˜åŒ–**
   - Soft-NMS
   - DIoU-NMS
   - è‡ªé€‚åº”NMS

2. **ç½®ä¿¡åº¦æ ¡å‡†**
   - Temperature Scaling
   - Platt Scaling

### 10.3 è®ºæ–‡æ’°å†™è¦ç‚¹

1. **å¼•è¨€éƒ¨åˆ†**
   - ç ”ç©¶èƒŒæ™¯å’Œæ„ä¹‰
   - ç›¸å…³å·¥ä½œç»¼è¿°
   - æœ¬æ–‡è´¡çŒ®

2. **æ–¹æ³•éƒ¨åˆ†**
   - YOLOv8æ¶æ„è¯¦è§£
   - æ”¹è¿›ç­–ç•¥è¯´æ˜
   - è®­ç»ƒç»†èŠ‚

3. **å®éªŒéƒ¨åˆ†**
   - æ•°æ®é›†ä»‹ç»
   - å®éªŒè®¾ç½®
   - è¯„ä»·æŒ‡æ ‡
   - æ¶ˆèå®éªŒ
   - å¯¹æ¯”å®éªŒ
   - å¯è§†åŒ–åˆ†æ

4. **ç»“è®ºéƒ¨åˆ†**
   - ä¸»è¦å‘ç°
   - å±€é™æ€§
   - æœªæ¥å·¥ä½œ

### 10.4 å¸¸è§é—®é¢˜FAQ

**Q1: æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠ?**
- å‡å°batch size
- ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
- ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
- å‡å°å›¾åƒå°ºå¯¸

**Q2: è®­ç»ƒæ”¶æ•›æ…¢?**
- è°ƒæ•´å­¦ä¹ ç‡
- æ£€æŸ¥æ•°æ®å¢å¼ºæ˜¯å¦è¿‡å¼º
- ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
- å¢åŠ warm-upè½®æ•°

**Q3: è¿‡æ‹Ÿåˆæ€ä¹ˆåŠ?**
- å¢å¼ºæ•°æ®å¢å¼º
- å¢åŠ æ­£åˆ™åŒ–(weight_decay)
- ä½¿ç”¨Dropout
- æ—©åœæ³•

**Q4: å°ç›®æ ‡æ£€æµ‹æ•ˆæœå·®?**
- å¢åŠ è¾“å…¥å›¾åƒå°ºå¯¸
- ä½¿ç”¨å¤šå°ºåº¦è®­ç»ƒå’Œæµ‹è¯•
- å¢å¼ºå°ç›®æ ‡çš„æ•°æ®å¢å¼º
- è°ƒæ•´ç‰¹å¾é‡‘å­—å¡”

**Q5: å¦‚ä½•æé«˜æ¨ç†é€Ÿåº¦?**
- ä½¿ç”¨æ›´å°çš„æ¨¡å‹(YOLOv8n)
- æ¨¡å‹é‡åŒ–(INT8)
- å¯¼å‡ºä¸ºTensorRT
- æ‰¹é‡æ¨ç†

---

## åä¸€ã€å‚è€ƒèµ„æº

### 11.1 å®˜æ–¹æ–‡æ¡£
- [YOLOv8å®˜æ–¹æ–‡æ¡£](https://docs.ultralytics.com/)
- [PyTorchå®˜æ–¹æ–‡æ¡£](https://pytorch.org/docs/)

### 11.2 ç›¸å…³è®ºæ–‡
- YOLOv8: Ultralytics YOLOv8
- YOLOv7: Trainable bag-of-freebies
- YOLOv5: Object Detection
- Focal Loss for Dense Object Detection
- CBAM: Convolutional Block Attention Module

### 11.3 æœ‰ç”¨çš„å·¥å…·
- **æ ‡æ³¨å·¥å…·**: LabelImg, CVAT, Roboflow
- **å¯è§†åŒ–**: TensorBoard, Weights & Biases
- **æ¨¡å‹è½¬æ¢**: ONNX, TensorRT
- **è¶…å‚æ•°ä¼˜åŒ–**: Optuna, Ray Tune

### 11.4 ä»£ç ä»“åº“
- [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics)
- [YOLOv5](https://github.com/ultralytics/yolov5)
- [MMDetection](https://github.com/open-mmlab/mmdetection)

---

## é™„å½•:å®Œæ•´è®­ç»ƒæµç¨‹ç¤ºä¾‹

```bash
# 1. ç¯å¢ƒå‡†å¤‡
conda create -n yolov8_driver python=3.9
conda activate yolov8_driver
pip install ultralytics torch torchvision

# 2. ä¸‹è½½æ•°æ®é›†
# æ‰‹åŠ¨ä»ç™¾åº¦ç½‘ç›˜ä¸‹è½½ datasets_3.zip

# 3. è§£å‹æ•°æ®é›†
unzip datasets_3.zip

# 4. æ•°æ®åˆ†æ
python data_analysis.py

# 5. åŸºçº¿è®­ç»ƒ
python train_baseline.py

# 6. ä¼˜åŒ–è®­ç»ƒ
python train_optimized.py

# 7. è¯„ä¼°æ¨¡å‹
python evaluate.py

# 8. å¯è§†åŒ–ç»“æœ
python visualize_predictions.py

# 9. ç»˜åˆ¶è®­ç»ƒæ›²çº¿
python monitor_training.py

# 10. æ¨¡å‹å¯¼å‡º
python export_model.py

# 11. æ¨ç†æµ‹è¯•
python inference.py
```

---

**ç¥ä½ åœ¨å¤§ä½œä¸šä¸­å–å¾—ä¼˜å¼‚æˆç»©!** ğŸ“

å¦‚æœ‰ä»»ä½•é—®é¢˜,è¯·éšæ—¶æŸ¥é˜…æœ¬æ–‡æ¡£æˆ–å‚è€ƒç›¸å…³èµ„æºã€‚å»ºè®®æŒ‰ç…§æ–‡æ¡£ä¸­çš„æ­¥éª¤é€æ­¥å®æ–½,è®°å½•æ¯æ¬¡å®éªŒçš„ç»“æœ,è¿™æ ·å¯ä»¥æ›´å¥½åœ°åˆ†æå’Œæ”¹è¿›æ¨¡å‹ã€‚
